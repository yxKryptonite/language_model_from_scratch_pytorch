{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import lgg_model\n",
    "from lgg_model import softmax\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vanilla_LSTM(\n",
       "  (Embedding): Embedding(709, 100)\n",
       "  (LSTM): LSTM(100, 100, num_layers=4, batch_first=True)\n",
       "  (Linear): Linear(in_features=100, out_features=709, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgg_model_path = input(\"请输入想使用的语言模型(无需添加后缀)：\")\n",
    "lgg_model_path = 'lgg_model_paths/' + lgg_model_path\n",
    "lgg_model = torch.load(lgg_model_path)\n",
    "lgg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_path = input(\"请使用想使用的词汇库(无需添加后缀)：\")\n",
    "word_model_path = 'word_model_paths/' + word_model_path\n",
    "word_model = Word2Vec.load(word_model_path)\n",
    "wv = word_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "帝若兮带上萧！\n",
      "带长剑兮，首身离兮心不惩。\n",
      "诚既兮又以武，终强兮不可凌。\n",
      "身既死兮神兮剑夜鸣夜之遗介兮，心日丘之善恶？\n",
      "民总美之菹艰兮，非余心之所。\n",
      "老冉冉其将至兮，恐修名之不立。\n",
      "朝饮木兰之坠兮，夕秋菊之落英。\n",
      "苟余情其信姱以作？怨将不群兮，伤独马此先桑。\n",
      "济皇翼其杂路兮，及修行兮。\n",
      "广立而心后以远兮，路观极兮下极。\n",
      "余兮浩甲。\n",
      "高美之可。\n",
      "望三五以为兮，指彭咸以为。\n",
      "夫何极而不至兮，故南人之知其相接。\n",
      "众不可户说兮，孰云察余之善恶？\n",
      "民好恶其不同兮，惟此党人其独异！\n",
      "户服艾以盈要兮，谓幽兰其不可佩。\n",
      "览谗乎！\n",
      "忠何罪以遇兮，亦非余心之所志。\n",
      "行不群以兮，又众兆之所也。\n",
      "壹心而不豫兮，羌不可保也。\n",
      "时於天结而诒。\n",
      "蹇蹇之烦冤兮，而不发。\n",
      "申以舒中情兮，志沉而莫达。\n",
      "愿言於浮云兮，遇丰隆而不将。\n",
      "因归鸟而致辞兮，羌高而难当。\n",
      "高辛之灵兮，遭玄鸟而致诒。\n",
      "欲变节以从俗兮，易初而屈志。\n",
      "独历年而离愍兮，羌心犹未化。\n",
      "宁发郁其若杂与君兮何不惩。\n",
      "诚既兮又宜，子慕予兮善。\n",
      "乘赤兮从文，辛夷车兮结桂旗。\n",
      "被石兰兮带杜衡，折芳兮遗所思。\n",
      "独亦余独美其变易兮，又何可以淹留？\n",
      "兰芷变而不芳兮，亦前世而无\n",
      "Generation finished.\n"
     ]
    }
   ],
   "source": [
    "words = input(\"请输入初始文本：\")\n",
    "del_lst = []\n",
    "lst = list(words)\n",
    "\n",
    "for i in lst:\n",
    "    if i not in wv.key_to_index:\n",
    "        del_lst.append(i)\n",
    "for i in del_lst:\n",
    "    lst.remove(i)\n",
    "\n",
    "data = np.array([])\n",
    "for i in lst:\n",
    "    data = np.append(data, wv.key_to_index[i])\n",
    "\n",
    "count = int(input(\"请输入想要生成的字(词)数：\"))\n",
    "\n",
    "for i in lst:\n",
    "    print(i, end='')\n",
    "\n",
    "for i in range(count):\n",
    "    data = np.stack((data,))\n",
    "    x = torch.Tensor(data)\n",
    "    x = x.to(torch.long)\n",
    "    y = lgg_model(x)[0][-1]\n",
    "    p = y.detach().numpy()\n",
    "    p = softmax(p)\n",
    "\n",
    "    idx = np.random.choice(np.arange(len(wv)), p=p)\n",
    "    new_word = wv.index_to_key[idx]\n",
    "    print(new_word, end='')\n",
    "\n",
    "    lst.append(new_word)\n",
    "    data = np.append(data, idx)\n",
    "\n",
    "print('\\nGeneration finished.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
